runMode = "BATCH"
dataSource = "KAFKA"
bridgeType="CUSTOM"
singleRun=true
kafka.consumer.maxRecordSize=150
kafka.consumer.waitBetweenPolls=100
#Kafka Stream
#if your application is streaming data from HDFS, provide Topic/partitions details
#consumerGroup - Kafka consumer group name. If you have multiple instances of consumers running,
#they should have the same consumer group name
#batchTime - duration of each batch
#streamsInfo - It is a list of streams that you want Application Manager to create
#streamsInfo.name - name of Kafka stream. Workflow components will provide this name if they are interested in this stream
#streamsInfo.topicName - name of Kafka topic
kafkaTopicInfo = {
  consumerGroup = "kafkaPassThroughWorkFlow"
  maxRatePerPartition: 970
  batchTime = "5"
  auto.offset.reset = "earliest"
  consumerParams = {
    test="set"
    session.timeout.ms=100000
  }
  streamsInfo = [{
    name = "hdfsStream"
    topicName = "kafkaTopic"
    validation = {
      columns = ["router","interface","oid","eventdate","elapsetime","inbytes","outbytes"]
      datatypes = ["String","String","Integer","Date","Long","Double","Double"]
      dateFormat = "yyyy-MM-dd HH:mm:ss"
      delimiter = "|"
      minimumColumn = 7
      rules = {}
    }
  }]
}

transactions = [{
  transactionName = "com.verizon.bda.trapezium.framework.apps.KafkaTxnPassThrough"
  inputStreams = [{
    name: "hdfsStream"
  }]
  persistStreamName = "hdfsFiltered"
  isPersist = "false"
}, {
  transactionName = "com.verizon.bda.trapezium.framework.apps.KafkaTxnPassThrough"
  inputStreams = [{
    name: "hdfsFiltered"
  }]
  persistStreamName = "hdfsDerived"
  isPersist = "false"
}, {
  transactionName = "com.verizon.bda.trapezium.framework.apps.KafkaTxnPassThrough"
  inputStreams = [{
    name: "hdfsDerived"
  }]
  persistStreamName = "hdfsAnomalies"
  isPersist = "true"
}]
