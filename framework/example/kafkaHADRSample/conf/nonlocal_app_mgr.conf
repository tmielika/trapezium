#log level for your application
logLevel = "DEBUG"

#appName will be used as Spark Application name.
#You can use this name to find your application on Yarn
appName = "ApplicationManager"

#appSchema will be used to access schema.
#Provide the schema your workflows will connect to persist, e.g., hive schema
persistSchema = "app_mgr"

#Application Manager will serialize objects to make sure that components are serializable
#Make sure you provide a directory which user has write access to
tempDir = "/tmp/"

#Running dependencies chain
#Default value is false
enable.Dependencies=true

sparkConf = {
  #Kryo Serializer
  #If you use Kryo serialization, set this class to register your custom classes with Kryo.
  #This property is useful if you need to register your classes in a custom way, e.g. to specify a custom field serializer.
  #Otherwise spark.kryo.classesToRegister is simpler
  ##kryoSerializer = ""

  #If you use Kryo serialization, give a comma-separated list of custom class names to register with Kryo
  kryoRegistratorClass = "com.verizon.bda.trapezium.framework.utils.EmptyRegistrator"
  #Akka Frame Size
  #Maximum message size to allow in "control plane" communication (for serialized tasks and task results), in MB.
  #Increase this if your tasks need to send back large results to the driver (e.g. using collect() on a large dataset).
  spark.akka.frameSize = 100
}

#ZooKeeper connection
zookeeperList = "127.0.0.1:2181"

#Kafka Brokers
kafkabrokers = "127.0.0.1:9092"

#ApplicationStartupClass - Has to be implemented by the Vertical
applicationStartupClass = "com.verizon.bda.trapezium.framework.apps.TestManagerStartup"

#FileSystem prefix allows application manager to read file from different file systems(hdfs/S3/file)
#fileSystemPrefix = "hdfs://"
fileSystemPrefix = ""

kafkaConf = {
  bootstrap.servers="localhost:9092,localhost:9092"
  batch.num.messages = 5000
  queue.buffering.max.ms = 1000
  producer.type = "async"
  key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
  value.serializer = "org.apache.kafka.common.serialization.StringSerializer"
  acks.config = "0"
  enable.auto.commit=false
  retries.config = "0"
}

hadoopConf = {
  parquet.enable.summary-metadata = "false"
}
